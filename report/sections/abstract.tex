\begin{abstract}
Policy microsimulation requires comprehensive microdata combining demographic, income, and wealth information, yet such data rarely coexist in a single survey. Statistical matching addresses this gap by imputing variables from a donor survey onto a receiver survey. We investigate whether deep learning models can improve upon Quantile Random Forests (QRF), the current state-of-the-art for imputing net worth from the Survey of Consumer Finances (SCF) onto the Current Population Survey (CPS). We evaluate four deep learning architectures: RealNVP (normalizing flows), Mixture Density Networks (MDN), TabSyn (VAE with latent diffusion), and TabPFN (a transformer-based foundation model). Using 3-fold cross-validation with quantile loss and distributional accuracy metrics (Wasserstein distance and Kolmogorov-Smirnov statistic), TabPFN achieves the best performance across all metrics. TabPFN attains 6\% lower median quantile loss than QRF ($2.36 \pm 0.04$ vs. $2.51 \pm 0.01$) and 12\% lower Wasserstein distance (415,000 vs. 472,000), demonstrating that transformer-based foundation models can outperform both traditional ensemble methods and explicitly generative deep learning approaches for survey imputation. However, TabPFN's high computational cost (approximately 12 hours for full CPS imputation compared to QRF's few minutes) currently limits practical adoption for daily workflows. RealNVP and TabSyn prove unsuitable in their current configurations, with Wasserstein distances exceeding 12 million, while MDN performs competitively but does not achieve any practical improvements. These findings suggest that pre-trained models leveraging in-context learning offer a promising direction for statistical matching tasks, with potential for broader adoption as inference efficiency improves.\footnote{Code is available at \url{https://github.com/juaristi22/cs156-pipeline}.}
\end{abstract}
