\section{Conclusion}
\label{sec:conclusion}

\subsection{Summary}

This paper investigated whether deep learning models can improve upon Quantile Random Forests for the task of imputing net worth from the Survey of Consumer Finances onto the Current Population Survey. We evaluated four deep learning architectures, RealNVP (normalizing flows), Mixture Density Networks, TabSyn (VAE with latent diffusion), and TabPFN (transformer-based foundation model), against a QRF baseline. Benchmarking metrics included cross-validation quantile loss and distributional accuracy metrics.

TabPFN emerges as the best performer, achieving a median quantile loss of $2.36 \pm 0.04$ (6\% lower than QRF's $2.51 \pm 0.01$) and the best distributional accuracy with a Wasserstein distance of 415,000 (12\% lower than QRF's 472,000). Unlike the generative approaches that learn parameters through gradient descent, TabPFN leverages a pre-trained transformer that performs in-context learning, effectively averaging over a prior distribution of data-generating processes. This suggests that foundation models trained on diverse synthetic data can effectively transfer to real-world statistical matching tasks.

However, TabPFN's high computational cost (approximately 12 hours to impute net worth onto the full CPS dataset) currently limits its practical adoption for daily imputation workflows. QRF remains a strong and computationally efficient baseline (completing in under 2 minutes), making it the preferred choice when rapid turnaround is essential. MDN shows moderate performance but does not surpass either TabPFN or QRF on any metric.

In contrast, RealNVP and TabSyn prove unsuitable in their current configurations. Both models produce imputed distributions with Wasserstein distances exceeding 12 million, orders of magnitude worse than the best performers. RealNVP generates a symmetric distribution missing the characteristic right skew of wealth, while TabSyn over-generates extreme values in both tails.

Overall, TabPFN demonstrates that transformer-based foundation models can achieve state-of-the-art performance for survey imputation, modestly outperforming traditional ensemble methods. As inference efficiency improves through algorithmic advances or hardware acceleration, TabPFN may become not only the most accurate but also a practically feasible choice for routine imputation workflows.

\subsection{Pipeline Overview}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/pipeline.jpg}
\caption{Overview of the imputation and model benchmarking pipeline.}
\label{fig:pipeline}
\end{figure}

The imputation pipeline developed in this work consists of five stages. First, the SCF and CPS datasets are loaded and harmonized by filtering to common predictor variables: age, gender, race, and income sources (employment, interest/dividend, and pension income). Next, net worth values undergo inverse hyperbolic sine (asinh) transformation to handle the heavy-tailed distribution, while categorical variables are encoded appropriately for each model (one-hot encoding for neural networks, native categorical handling for QRF).

Model evaluation proceeds through three-fold cross-validation on the SCF, assessing each model's ability to predict held-out net worth values by computing quantile loss at $\tau \in \{0.25, 0.50, 0.75\}$. Following cross-validation, models are trained on the full SCF dataset and used to impute net worth onto all CPS observations, with stochastic sampling preserving distributional properties for generative models. Finally, imputed CPS distributions are compared against the SCF donor distribution using Wasserstein distance and the Kolmogorov-Smirnov statistic to assess distributional fidelity.

An additional step prior to the pipeline itself involved adapting TabSyn's architecture to condition its diffusion sampling on receiver observations, a necessary modification for the statistical matching context. This entailed altering the model's input structure and preprocessing procedure, as well as supporting conditioning on a dataset other than the one used to train through Symlinks to ensure that generated samples reflected the predictor values present in the receiver dataset.

\subsection{Reproducibility and Future Work}

All code for this analysis is available at \url{https://github.com/juaristi22/cs156-pipeline}, including TabSyn's adapted implementations and the Jupyter notebook with the full pipeline. The SCF data is publicly available from the Federal Reserve (\url{https://www.federalreserve.gov/econres/scfindex.htm}), and the CPS data can be accessed in PolicyEngine's public huggingface repository (\url{https://huggingface.co/policyengine/policyengine-us-data/blob/main/cps\_2023.h5}).

Future work should explore whether TabPFN's performance can be further improved through ensemble methods or alternative subsampling strategies. Additionally, investigating TabPFN's performance on other statistical matching problems (beyond wealth imputation) would help establish its generalizability. For the generative approaches, understanding why normalizing flows and diffusion models struggle with heavy-tailed distributions could inform architectural modifications. As TabPFN's inference efficiency improves, it may become the preferred choice for practitioners seeking both accuracy and practicality. Finally, extending the predictor set in the case that data collection and survey design is extended to additional variables may improve imputation accuracy across all methods.